{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang Di Halaman Persentative Penambangan Data\u00b6 Nama : Akhmad Shulthon Fathoni NRP : 140411100136 Kelas : Penambangan Data 5E Dosen Pengampu : MULA'AB, S.Si., M.Kom Jurusan : Teknik Informatika Alamat : Desa Bandungan, Kec. Pakong, Kab. Pamekasan, Kep. Madura, Jawa Timur","title":"Memo"},{"location":"#selamat-datang-di-halaman-persentative-penambangan-data","text":"Nama : Akhmad Shulthon Fathoni NRP : 140411100136 Kelas : Penambangan Data 5E Dosen Pengampu : MULA'AB, S.Si., M.Kom Jurusan : Teknik Informatika Alamat : Desa Bandungan, Kec. Pakong, Kab. Pamekasan, Kep. Madura, Jawa Timur","title":"Selamat Datang Di Halaman Persentative Penambangan Data\u00b6"},{"location":"Fuzzy_C/","text":"","title":"Fuzzy C"},{"location":"Regresi_Linier/","text":"","title":"Regresi Linier"},{"location":"clustering/","text":"","title":"Clustering"},{"location":"decission_tree/","text":"DECISSION TREE Pengertian Decission Tree \u200b Decission Tree atau bisa disebut dengan Pohon Keputusan adalah sebuah algoritma dalam meramal atau menentukan keputusan akhir dari banyaknya data yang digunakan atau dibutuhkan untuk akhir dari kumpulan data. Dalam basis data ini dapat dipergunakan untuk memprediksi hasil akhir data. \u200b Dalam beberapa kasus Penggunaan decission tree dapat dimanfaatkan dalam beberapa instansi, perusahaan, bahkan sistem penilaian otomatis, dan banyak lagi. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. Manfaat utama dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. \u200b Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Algoritma Dasar Pembelajaran Pohon Keputusan Kebanyakan algoritma untuk pembelajaran pohon keputusan adalah variasi dari algoritma intinya yang menggunakan pencarian rakus ( greedy ) dari atas ke bawah terhadap ruang kemungkinan pohon keputusan. Langkah-langkah yang dilakukan yaitu, Tentukan atribut terbaik untuk root dari tree . Setiap instan dari atribut dievaluasi menggunakan sebuah tes statistik untuk menentukan seberapa bagus atribut tersebut mengklasifikasi sampel latihan. Turunan dari node root dibuat untuk setiap kemungkinan nilai dari atribut Sampel latihan kemudian diurutkan berdasarkan node turunan. Seluruh proses kemudian diulang menggunakan sampel latihan yang berhubungan dengan setiap node turunan untuk menentukan atribut terbaik untuk dites di pohon. Entropi Untuk menentukan information gain secara tepat, dimulai dengan menentukan sebuah ukuran, dalam teori informasi disebut entropi , yang mengkarakterisasikan kemurnian/ketakmurnian dari sebuah koleksi acak dari sampel. $$ \\text {Entropi }(S)=\\sum_{i=1}^{c}-p_{i} \\log {2} p {i} $$ yang mana pi adalah proporsi klas i terhadap S. Information Gain Untuk menentukan atribut terbaik caranya dengan menggunakan properti statistik yang disebut information gain , yang mengukur seberapa bagus atribut tersebut memisahkan sampel latihan menurut klasifikasi targetnya. Dari nilai entropi kemudian dapat dihitung information gain , Gain(S, A) dari sebuah atribut A relatif terhadap kumpulan sampel S, dengan cara berikut, $$ \\operatorname{Gain}(S, A) \\equiv \\text { Entropi }(S)-\\sum_{v \\in V \\text { alues }(A)} \\frac{\\left|S_{v}\\right|}{|S|} \\operatorname{Entropi}\\left(S_{v}\\right) $$ Values(A) adalah set dari semua kemungkinan nilai untuk atribut A , Sv adalah subset dari S yang mana atribut A memiliki nilai v .","title":"Decision Tree"},{"location":"decission_tree/#decission-tree","text":"","title":"DECISSION TREE"},{"location":"decission_tree/#pengertian-decission-tree","text":"\u200b Decission Tree atau bisa disebut dengan Pohon Keputusan adalah sebuah algoritma dalam meramal atau menentukan keputusan akhir dari banyaknya data yang digunakan atau dibutuhkan untuk akhir dari kumpulan data. Dalam basis data ini dapat dipergunakan untuk memprediksi hasil akhir data. \u200b Dalam beberapa kasus Penggunaan decission tree dapat dimanfaatkan dalam beberapa instansi, perusahaan, bahkan sistem penilaian otomatis, dan banyak lagi. Konsep dari pohon keputusan adalah mengubah data menjadi decision tree dan aturan-aturan keputusan. Manfaat utama dari penggunaan decision tree adalah kemampuannya untuk mem- break down proses pengambilan keputusan yang kompleks menjadi lebih simple, sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. \u200b Decision tree juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target.","title":"Pengertian Decission Tree"},{"location":"decission_tree/#algoritma-dasar-pembelajaran-pohon-keputusan","text":"Kebanyakan algoritma untuk pembelajaran pohon keputusan adalah variasi dari algoritma intinya yang menggunakan pencarian rakus ( greedy ) dari atas ke bawah terhadap ruang kemungkinan pohon keputusan. Langkah-langkah yang dilakukan yaitu, Tentukan atribut terbaik untuk root dari tree . Setiap instan dari atribut dievaluasi menggunakan sebuah tes statistik untuk menentukan seberapa bagus atribut tersebut mengklasifikasi sampel latihan. Turunan dari node root dibuat untuk setiap kemungkinan nilai dari atribut Sampel latihan kemudian diurutkan berdasarkan node turunan. Seluruh proses kemudian diulang menggunakan sampel latihan yang berhubungan dengan setiap node turunan untuk menentukan atribut terbaik untuk dites di pohon.","title":"Algoritma Dasar Pembelajaran Pohon Keputusan"},{"location":"decission_tree/#entropi","text":"Untuk menentukan information gain secara tepat, dimulai dengan menentukan sebuah ukuran, dalam teori informasi disebut entropi , yang mengkarakterisasikan kemurnian/ketakmurnian dari sebuah koleksi acak dari sampel. $$ \\text {Entropi }(S)=\\sum_{i=1}^{c}-p_{i} \\log {2} p {i} $$ yang mana pi adalah proporsi klas i terhadap S.","title":"Entropi"},{"location":"decission_tree/#information-gain","text":"Untuk menentukan atribut terbaik caranya dengan menggunakan properti statistik yang disebut information gain , yang mengukur seberapa bagus atribut tersebut memisahkan sampel latihan menurut klasifikasi targetnya. Dari nilai entropi kemudian dapat dihitung information gain , Gain(S, A) dari sebuah atribut A relatif terhadap kumpulan sampel S, dengan cara berikut, $$ \\operatorname{Gain}(S, A) \\equiv \\text { Entropi }(S)-\\sum_{v \\in V \\text { alues }(A)} \\frac{\\left|S_{v}\\right|}{|S|} \\operatorname{Entropi}\\left(S_{v}\\right) $$ Values(A) adalah set dari semua kemungkinan nilai untuk atribut A , Sv adalah subset dari S yang mana atribut A memiliki nilai v .","title":"Information Gain"},{"location":"missing_value/","text":"MISSING VALUE IN DATA MINING Apa itu Missing Value dalam Data Minning? Missing value dapat menandakan sejumlah pengrtian yang berbeda. Mungkin pada bagian (nilai) tidak berlaku, tindakan yang tidak pernah terjadi, atau data tidak tersedia. Bisa jadi orang yang memasukkan data tidak tahu nilai yang benar, atau tidak peduli jika bidang tidak diisi. Namun, ada skenario penambangan data di mana nilai yang hilang memberikan informasi penting. Arti dari nilai-nilai yang hilang sangat tergantung pada konteks. Secara umum, Layanan Analisis memperlakukan nilai-nilai yang hilang sebagai informatif dan menyesuaikan probabilitas untuk memasukkan nilai-nilai yang hilang ke dalam perhitungannya. Mekanisme dalam Mengatasi Missing Value Prosedur Berbasis Unit Prosedur ini hanya analisis data yang lengkap. Sedangkan yang tidak lengkap akan diabaikan, atau bahkan dihilangkan. Metode ini memuaskan bila jumlah missing tidak terlalu besar, tapi prosedur ini menjadi tidak efisien jika persentase missing data lebih dari (n2/2).100 Prosedur Berbasis Imputasi Prosedur ini adalah cara yang umum dan fleksibel. Biasanya pemegang data mengganti dengan nilai-nilai yang berdekatan, atau dengan memasukkan nilai rata-rata yang telah ditentukan sebelumnya. Klasifikasi menggunakan Metode KNN (K-Nearest Neighbor) klasifikasi menggunakan K-Nearest Neighbor dapat dilakukan dalam phyton seperti berikut Pertama , import package pandas dan numpy import pandas as pd import numpy as np Kedua , menginput dan membaca 5 data teratas dari file phpelnJ6y.csv australia = pd . read_csv ( phpelnJ6y.csv ) australia . head () Maka output yang didapatkan yaitu A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 A15 0 1 65 168 2 4 4 39 0 0 1 1 2 32 161 0 1 0 72 123 2 8 4 5 0 0 1 0 2 53 1 0 2 0 142 52 1 4 4 31 0 0 1 1 2 98 1 0 3 0 60 169 1 5 3 1 1 1 12 1 2 1 1 1 4 1 44 134 2 6 4 46 1 1 15 0 2 18 68 1 Ketiga , menampilkan informasi tentang jenis data Cryotherapy. australia . info () Output : class pandas.core.frame.DataFrame RangeIndex: 690 entries, 0 to 689 Data columns (total 15 columns): A1 690 non-null int64 A2 690 non-null int64 A3 690 non-null int64 A4 690 non-null int64 A5 690 non-null int64 A6 690 non-null int64 A7 690 non-null int64 A8 690 non-null int64 A9 690 non-null int64 A10 690 non-null int64 A11 690 non-null int64 A12 690 non-null int64 A13 690 non-null int64 A14 690 non-null int64 A15 690 non-null int64 dtypes: int64(15) memory usage: 80.9 KB Berdasarkan output diatas, maka dapat diketahui bahwa dari data tipe datanya integer . Keempat , menentukan variabel independen dari data sehingga, menghapus variabel dependen yaitu Result of Treatment. x = australia . drop ([ A15 ], axis = 1 ) x . head () Output : A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 0 1 65 168 2 4 4 39 0 0 1 1 2 32 161 1 0 72 123 2 8 4 5 0 0 1 0 2 53 1 2 0 142 52 1 4 4 31 0 0 1 1 2 98 1 3 0 60 169 1 5 3 1 1 1 12 1 2 1 1 4 1 44 134 2 6 4 46 1 1 15 0 2 18 68 Kelima , menampilkan data variabel dependen yaitu Result of Treatment. y = australia [ A15 ] y . head () Output : 0 0 1 0 2 0 3 1 4 1 Name: A15, dtype: int64 Keenam , membagi data training dan data training. from sklearn.model_selection import train_test_split x_train , x_test , y_train , y_test = train_test_split ( x , y , test_size = 0.2 , random_state = 123 ) Ketujuh , mengubah skala data. from sklearn.preprocessing import StandardScaler scaler = StandardScaler () scaler . fit ( x_train ) x_train = scaler . transform ( x_train ) x_test = scaler . transform ( x_test ) Kedelapan , Mengaktifkan fungsi klasifikasi. from sklearn.neighbors import KNeighborsClassifier klasifikasi = KNeighborsClassifier ( n_neighbors = 5 ) Kesembilan , Menginput data training pada fungsi klasifikasi. klasifikasi . fit ( x_train , y_train ) __Output : __ KNeighborsClassifier(algorithm= auto , leaf_size=30, metric= minkowski , metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights= uniform ) Kesepuluh , Menentukan hasil prediksi dari x_test. y_pred = klasifikasi . predict ( x_test ) y_pred Output array([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0], dtype=int64) Kesebelas , menentukan probabilitas dari hasil prediksi. klasifikasi . predict_proba ( x_test ) Output array([[0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [0.2, 0.8], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [0.2, 0.8], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.6, 0.4], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [1. , 0. ], [0.8, 0.2], [0.6, 0.4], [0.6, 0.4], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0.4, 0.6], [0.8, 0.2], [0.2, 0.8], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.4, 0.6], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.6, 0.4], [0.2, 0.8], [0.8, 0.2], [0.4, 0.6], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.2, 0.8], [0. , 1. ], [0. , 1. ], [1. , 0. ], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [0.2, 0.8], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0.4, 0.6], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0. , 1. ], [0.4, 0.6], [0.8, 0.2], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0.6, 0.4], [0. , 1. ], [0.8, 0.2], [0.8, 0.2], [0.4, 0.6], [0.2, 0.8], [0.2, 0.8], [0.4, 0.6], [0.8, 0.2], [0.4, 0.6], [0. , 1. ], [0. , 1. ], [1. , 0. ], [0.4, 0.6], [0.2, 0.8], [0.2, 0.8], [0.2, 0.8], [0.4, 0.6], [0. , 1. ], [1. , 0. ], [0.8, 0.2], [0.8, 0.2], [1. , 0. ], [0.6, 0.4], [0.8, 0.2], [0.6, 0.4], [0. , 1. ], [0.2, 0.8], [1. , 0. ], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0.2, 0.8], [0.6, 0.4]]) Keduabelas , menampilkan confussion matrix hasil prediksi klasifikasi (Report). from sklearn.metrics import classification_report , confusion_matrix print ( confusion_matrix ( y_test , y_pred )) print ( ----------------------------------------------------------------------- ) print ( classification_report ( y_test , y_pred )) Output [[73 11] [ 9 45]] ----------------------------------------------------------------------- precision recall f1-score support 0 0.89 0.87 0.88 84 1 0.80 0.83 0.82 54 accuracy 0.86 138 macro avg 0.85 0.85 0.85 138 weighted avg 0.86 0.86 0.86 138 Ketigabelas , untuk mengitung nilai akurasi maka import accuracy score. from sklearn.metrics import accuracy_score accuracy = accuracy_score ( y_test , y_pred ) accuracy Output 0.855072463768116 Berdasarkan nilai output diatas , maka dapat diketahui bahwa nilai akurasi yang didapatkan yaitu 0.85507 . Sumber Data yang saya ambil berada di: https://www.openml.org/d/40981 Sumber Bahasan: https://docs.microsoft.com/en-us/analysis-services/data-mining/missing-values-analysis-services-data-mining https://medium.com/@16611130/klasifikasi-menggunakan-metode-knn-k-nearest-neighbor-dalam-python-a40e79a74101","title":"Missing Values Dan K - Nearest Neighbor"},{"location":"missing_value/#missing-value-in-data-mining","text":"","title":"MISSING VALUE IN DATA MINING"},{"location":"missing_value/#apa-itu-missing-value-dalam-data-minning","text":"Missing value dapat menandakan sejumlah pengrtian yang berbeda. Mungkin pada bagian (nilai) tidak berlaku, tindakan yang tidak pernah terjadi, atau data tidak tersedia. Bisa jadi orang yang memasukkan data tidak tahu nilai yang benar, atau tidak peduli jika bidang tidak diisi. Namun, ada skenario penambangan data di mana nilai yang hilang memberikan informasi penting. Arti dari nilai-nilai yang hilang sangat tergantung pada konteks. Secara umum, Layanan Analisis memperlakukan nilai-nilai yang hilang sebagai informatif dan menyesuaikan probabilitas untuk memasukkan nilai-nilai yang hilang ke dalam perhitungannya.","title":"Apa itu Missing Value dalam Data Minning?"},{"location":"missing_value/#mekanisme-dalam-mengatasi-missing-value","text":"","title":"Mekanisme dalam Mengatasi Missing Value"},{"location":"missing_value/#prosedur-berbasis-unit","text":"Prosedur ini hanya analisis data yang lengkap. Sedangkan yang tidak lengkap akan diabaikan, atau bahkan dihilangkan. Metode ini memuaskan bila jumlah missing tidak terlalu besar, tapi prosedur ini menjadi tidak efisien jika persentase missing data lebih dari (n2/2).100","title":"Prosedur Berbasis Unit"},{"location":"missing_value/#prosedur-berbasis-imputasi","text":"Prosedur ini adalah cara yang umum dan fleksibel. Biasanya pemegang data mengganti dengan nilai-nilai yang berdekatan, atau dengan memasukkan nilai rata-rata yang telah ditentukan sebelumnya.","title":"Prosedur Berbasis Imputasi"},{"location":"missing_value/#klasifikasi-menggunakan-metode-knn-k-nearest-neighbor","text":"klasifikasi menggunakan K-Nearest Neighbor dapat dilakukan dalam phyton seperti berikut Pertama , import package pandas dan numpy import pandas as pd import numpy as np Kedua , menginput dan membaca 5 data teratas dari file phpelnJ6y.csv australia = pd . read_csv ( phpelnJ6y.csv ) australia . head () Maka output yang didapatkan yaitu A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 A15 0 1 65 168 2 4 4 39 0 0 1 1 2 32 161 0 1 0 72 123 2 8 4 5 0 0 1 0 2 53 1 0 2 0 142 52 1 4 4 31 0 0 1 1 2 98 1 0 3 0 60 169 1 5 3 1 1 1 12 1 2 1 1 1 4 1 44 134 2 6 4 46 1 1 15 0 2 18 68 1 Ketiga , menampilkan informasi tentang jenis data Cryotherapy. australia . info () Output : class pandas.core.frame.DataFrame RangeIndex: 690 entries, 0 to 689 Data columns (total 15 columns): A1 690 non-null int64 A2 690 non-null int64 A3 690 non-null int64 A4 690 non-null int64 A5 690 non-null int64 A6 690 non-null int64 A7 690 non-null int64 A8 690 non-null int64 A9 690 non-null int64 A10 690 non-null int64 A11 690 non-null int64 A12 690 non-null int64 A13 690 non-null int64 A14 690 non-null int64 A15 690 non-null int64 dtypes: int64(15) memory usage: 80.9 KB Berdasarkan output diatas, maka dapat diketahui bahwa dari data tipe datanya integer . Keempat , menentukan variabel independen dari data sehingga, menghapus variabel dependen yaitu Result of Treatment. x = australia . drop ([ A15 ], axis = 1 ) x . head () Output : A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 0 1 65 168 2 4 4 39 0 0 1 1 2 32 161 1 0 72 123 2 8 4 5 0 0 1 0 2 53 1 2 0 142 52 1 4 4 31 0 0 1 1 2 98 1 3 0 60 169 1 5 3 1 1 1 12 1 2 1 1 4 1 44 134 2 6 4 46 1 1 15 0 2 18 68 Kelima , menampilkan data variabel dependen yaitu Result of Treatment. y = australia [ A15 ] y . head () Output : 0 0 1 0 2 0 3 1 4 1 Name: A15, dtype: int64 Keenam , membagi data training dan data training. from sklearn.model_selection import train_test_split x_train , x_test , y_train , y_test = train_test_split ( x , y , test_size = 0.2 , random_state = 123 ) Ketujuh , mengubah skala data. from sklearn.preprocessing import StandardScaler scaler = StandardScaler () scaler . fit ( x_train ) x_train = scaler . transform ( x_train ) x_test = scaler . transform ( x_test ) Kedelapan , Mengaktifkan fungsi klasifikasi. from sklearn.neighbors import KNeighborsClassifier klasifikasi = KNeighborsClassifier ( n_neighbors = 5 ) Kesembilan , Menginput data training pada fungsi klasifikasi. klasifikasi . fit ( x_train , y_train ) __Output : __ KNeighborsClassifier(algorithm= auto , leaf_size=30, metric= minkowski , metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights= uniform ) Kesepuluh , Menentukan hasil prediksi dari x_test. y_pred = klasifikasi . predict ( x_test ) y_pred Output array([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0], dtype=int64) Kesebelas , menentukan probabilitas dari hasil prediksi. klasifikasi . predict_proba ( x_test ) Output array([[0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [0.2, 0.8], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [0.2, 0.8], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.6, 0.4], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [1. , 0. ], [0.8, 0.2], [0.6, 0.4], [0.6, 0.4], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [0.4, 0.6], [0.8, 0.2], [0.2, 0.8], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.4, 0.6], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.4, 0.6], [1. , 0. ], [1. , 0. ], [1. , 0. ], [0.6, 0.4], [0.2, 0.8], [0.8, 0.2], [0.4, 0.6], [0.2, 0.8], [0. , 1. ], [1. , 0. ], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [0.2, 0.8], [0. , 1. ], [0. , 1. ], [1. , 0. ], [0. , 1. ], [0. , 1. ], [0.8, 0.2], [0.2, 0.8], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0.4, 0.6], [1. , 0. ], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0. , 1. ], [0.4, 0.6], [0.8, 0.2], [0.8, 0.2], [1. , 0. ], [1. , 0. ], [0.6, 0.4], [0. , 1. ], [0.8, 0.2], [0.8, 0.2], [0.4, 0.6], [0.2, 0.8], [0.2, 0.8], [0.4, 0.6], [0.8, 0.2], [0.4, 0.6], [0. , 1. ], [0. , 1. ], [1. , 0. ], [0.4, 0.6], [0.2, 0.8], [0.2, 0.8], [0.2, 0.8], [0.4, 0.6], [0. , 1. ], [1. , 0. ], [0.8, 0.2], [0.8, 0.2], [1. , 0. ], [0.6, 0.4], [0.8, 0.2], [0.6, 0.4], [0. , 1. ], [0.2, 0.8], [1. , 0. ], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0.8, 0.2], [1. , 0. ], [0. , 1. ], [0.6, 0.4], [0.2, 0.8], [0.6, 0.4]]) Keduabelas , menampilkan confussion matrix hasil prediksi klasifikasi (Report). from sklearn.metrics import classification_report , confusion_matrix print ( confusion_matrix ( y_test , y_pred )) print ( ----------------------------------------------------------------------- ) print ( classification_report ( y_test , y_pred )) Output [[73 11] [ 9 45]] ----------------------------------------------------------------------- precision recall f1-score support 0 0.89 0.87 0.88 84 1 0.80 0.83 0.82 54 accuracy 0.86 138 macro avg 0.85 0.85 0.85 138 weighted avg 0.86 0.86 0.86 138 Ketigabelas , untuk mengitung nilai akurasi maka import accuracy score. from sklearn.metrics import accuracy_score accuracy = accuracy_score ( y_test , y_pred ) accuracy Output 0.855072463768116 Berdasarkan nilai output diatas , maka dapat diketahui bahwa nilai akurasi yang didapatkan yaitu 0.85507 .","title":"Klasifikasi menggunakan Metode KNN (K-Nearest Neighbor)"},{"location":"missing_value/#sumber","text":"Data yang saya ambil berada di: https://www.openml.org/d/40981 Sumber Bahasan: https://docs.microsoft.com/en-us/analysis-services/data-mining/missing-values-analysis-services-data-mining https://medium.com/@16611130/klasifikasi-menggunakan-metode-knn-k-nearest-neighbor-dalam-python-a40e79a74101","title":"Sumber"},{"location":"statistik_deskriptif/","text":"Statistik Deskriptif Pengertian \u200b Statistik deskriptif adalah koefisien deskriptif singkat yang meringkas set data yang diberikan, yang dapat berupa representasi keseluruhan atau sampel populasi. Statistik deskriptif dipecah menjadi ukuran tendensi sentral dan ukuran variabilitas (sebaran). Ukuran tendensi sentral meliputi mean, median, dan mode, sedangkan ukuran variabilitas meliputi deviasi standar, varians, variabel minimum dan maksimum, dan quartile serta skewness. Tipe Statistik Deskriptif Rata Rata (Mean) \u200b Mean adalah pemusatan nilai tengah atau rata rata nilai dari beberapa banyak nilai data, mean hanya dapat digunakan pada nilai data selain nominal dan ordinal. Cara kerja mean adalah jumlah nilai seluruh data dibagi dengan banyaknya data, Rumusnya sebagai berikut: $$ Rataan =\\frac{x_{1}+x_{2}+x_{3}+\\ldots+x_{n}}{n} $$ Keterangan : xn = adalah data ke-n n = adalah jumlah data Median \u200b Median adalah mencari nilai yang berada di tengah suatu tumpukan data yang sudah melalui proses urutan data atau penyusunan data (ordered list). \u200b Keuntungan dasar dari median dalam menggambarkan data dibandingkan dengan rata-rata (sering hanya digambarkan sebagai \"rata-rata\") adalah bahwa ia tidak condong terlalu banyak oleh sebagian kecil dari nilai yang sangat besar atau kecil. \\mathrm{Me}=\\mathrm{Q}_{2}=\\left\\{\\begin{array}{l}{\\frac{x_{n+1}}{2}, \\text { jika n ganjil }} \\\\ {\\frac{\\frac{x_{n}}{2}+x_{\\frac{n}{2}+1}}{2}, \\text { jika n genap }}\\end{array}\\right. \\mathrm{Me}=\\mathrm{Q}_{2}=\\left\\{\\begin{array}{l}{\\frac{x_{n+1}}{2}, \\text { jika n ganjil }} \\\\ {\\frac{\\frac{x_{n}}{2}+x_{\\frac{n}{2}+1}}{2}, \\text { jika n genap }}\\end{array}\\right. Jika Dikelompokkan Q_{j}=L_{j}+i \\frac{\\frac{j}{4} n-f k}{f} Q_{j}=L_{j}+i \\frac{\\frac{j}{4} n-f k}{f} Dengan : Qj = Kuartil ke-j j = 1, 2, 3 i = Interval kelas Lj = Tepi bawah kelas Qj fk = Frekuensi kumulatif sebelum kelas Qj f = Frekuensi kelas Qj n = Banyak data. Mode (Modus) \u200b Modus adalah nilai yang mempunyai frekuensi terbesar dalam suatu kumpulan data. Modus berguna untuk mengetahui tingkat keseringan terjadinya suatu peristiwa. Modus dapat digunakan untuk semua skala pengukuran data mulai dari nominal hingga rasio. Meskipun demikian modus paling cocok digunakan untuk data yang diukur dengan skala pengukuran nominal. Rumus dalam mencari modus adalah: $$ \\mathrm{Mo}=\\mathrm{Tb}+\\mathrm{p} \\cdot\\left(\\frac{d_{1}}{d_{1}+d_{2}}\\right) $$ Keterangan: - Tb = Tepi bawah kelas modus - p = Panjang interval - d1 = selisih frekuensi kelas modus dengan frekuensi kelas sebelumnya - d2 = selisih frekuensi kelas modus dengan frekuensi kelas setelahnya Standart Deviasi \u200b Standar deviasi adalah ukuran atau nilai statistik yang digunakan untuk mengukur jumlah variasi serta sebaran dari sejumlah nilai data. \u200b Secara khusus semakin rendah standar deviasi maka semakin mendekati rata-rata, sebaliknya jika semakin tinggi maka semakin lebar rentang variasi datanya. s=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n}} s=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n}} Keterangan: xi = nilai x ke i x bar = nilai rata-rata dari x n = banyaknya data Varians \u200b Varians didefinisikan sebagai rata-rata dari skor penyimpangan kuadrat. dan variasi adalah nilai akar dari standart deviasi krn itu tidak terlalu beda jauh antara rumus tersebut. contohnya sebagai berikut: s^{2}=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n-1}} s^{2}=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n-1}} Quartile Quartile adalah pembagian 4 bagian data yang sama perbagiannya dan berada dalam salah satu dari 3 titik yang membagi rentang bagian data yang sama yang menjadikan, yang menjadikan Q1, Q2 = median, Q3. Q_{1}=x_{\\frac{1}{4}(n+1)} Q_{1}=x_{\\frac{1}{4}(n+1)} Q_{2}=x_{\\frac{1}{2}(n+1)} Q_{2}=x_{\\frac{1}{2}(n+1)} Q_{1}=x_{\\frac{3}{4}(n+1)} Q_{1}=x_{\\frac{3}{4}(n+1)} Skewness skewness adalah ukuran dari asimetri dari distribusi probabilitas dari variabel acak bernilai nyata tentang nilai tengahnya. Nilai skewness bisa positif atau negatif, atau tidak terdefinisi. Untuk distribusi unimodal , condong negatif biasanya menunjukkan bahwa ekor berada di sisi kiri distribusi, dan condong positif menunjukkan bahwa ekor berada di sebelah kanan. sk=\\frac{\\overline{X}-Me}{s} sk=\\frac{\\overline{X}-Me}{s} Keterangan: - X bar = Rata Rata nilai X - Me = Median Data - s = simpangan baku (standart deviasi) Penerapan Statistik Deskriptif Library Untuk yang pertama Siapkan data yang digunakan yaitu data sebanyak 500 dalam 5 fitur yaitu X1 s/d X2 dalam bentuk excel pemprosesannya menggunakan python dan membutuhkan library sebagai berikut: Pandas untuk manajemen data Scipy adalah kumpulan algoritma aritmatika lalu setelah itu mulai import library yang disiapkan tadi: import pandas as pd from scipy import stats Managemen data Selanjutnya olah Data yaitu olah data exel tadi, dengan kode berikut df = pd . read_excel ( data_M5.xlsx , usecols = [ 1 , 2 , 3 , 4 , 5 ]) Olahdata Selanjutnya olah Data menggunakan variabel sementara untuk hasil keseluruhan data yang akan diolah mulai dari mean,median,modus(mode),min max,standart deviasi, quartile, dan skewnes dari beberapa vitur dari file exel tadi for i in df : print ( --- %s --- % i ) #to print title Q1 = df [ i ] . quantile ( 0.25 ) print ( Q1 = , Q1 ) Q2 = df [ i ] . quantile ( 0.5 ) print ( Q2 = , Q2 ) Q3 = df [ i ] . quantile ( 0.75 ) print ( Q3 = , Q3 ) Rata = df [ i ] . mean () print ( Mean = , Rata ) Std_dev = statistics . stdev ( df [ i ]) print ( Std Dev = , Std_dev ) Skewness = df [ i ] . skew () print ( Skewness = , Skewness , \\n ) Hasil data dari olahan data tersebut menghasilkan data tersebut menghasilkan data sebagai berikut ketida dihasilkan menggunakan kolom: code: df . describe () outpunya : x1 x2 x3 x4 x5 count 100.000000 100.000000 100.000000 100.000000 100.000000 mean 65.370000 65.910000 53.940000 61.620000 67.470000 median 66.500000 68.500000 57.000000 60.000000 70.500000 std 20.868833 22.992794 24.068849 18.415946 21.003345 min 20.000000 21.000000 10.000000 16.000000 21.000000 25% 49.750000 47.000000 37.000000 47.750000 55.000000 50% 66.500000 68.500000 57.000000 60.000000 70.500000 75% 81.250000 86.250000 72.000000 75.250000 83.500000 max 100.000000 100.000000 100.000000 99.000000 100.000000 skew -0.164192 -0.279515 -0.085728 0.092857 -0.542891 Source Untuk file python ada di sini","title":"Statistik Deskriptif"},{"location":"statistik_deskriptif/#statistik-deskriptif","text":"","title":"Statistik Deskriptif"},{"location":"statistik_deskriptif/#pengertian","text":"\u200b Statistik deskriptif adalah koefisien deskriptif singkat yang meringkas set data yang diberikan, yang dapat berupa representasi keseluruhan atau sampel populasi. Statistik deskriptif dipecah menjadi ukuran tendensi sentral dan ukuran variabilitas (sebaran). Ukuran tendensi sentral meliputi mean, median, dan mode, sedangkan ukuran variabilitas meliputi deviasi standar, varians, variabel minimum dan maksimum, dan quartile serta skewness.","title":"Pengertian"},{"location":"statistik_deskriptif/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"statistik_deskriptif/#rata-rata-mean","text":"\u200b Mean adalah pemusatan nilai tengah atau rata rata nilai dari beberapa banyak nilai data, mean hanya dapat digunakan pada nilai data selain nominal dan ordinal. Cara kerja mean adalah jumlah nilai seluruh data dibagi dengan banyaknya data, Rumusnya sebagai berikut: $$ Rataan =\\frac{x_{1}+x_{2}+x_{3}+\\ldots+x_{n}}{n} $$ Keterangan : xn = adalah data ke-n n = adalah jumlah data","title":"Rata Rata (Mean)"},{"location":"statistik_deskriptif/#median","text":"\u200b Median adalah mencari nilai yang berada di tengah suatu tumpukan data yang sudah melalui proses urutan data atau penyusunan data (ordered list). \u200b Keuntungan dasar dari median dalam menggambarkan data dibandingkan dengan rata-rata (sering hanya digambarkan sebagai \"rata-rata\") adalah bahwa ia tidak condong terlalu banyak oleh sebagian kecil dari nilai yang sangat besar atau kecil. \\mathrm{Me}=\\mathrm{Q}_{2}=\\left\\{\\begin{array}{l}{\\frac{x_{n+1}}{2}, \\text { jika n ganjil }} \\\\ {\\frac{\\frac{x_{n}}{2}+x_{\\frac{n}{2}+1}}{2}, \\text { jika n genap }}\\end{array}\\right. \\mathrm{Me}=\\mathrm{Q}_{2}=\\left\\{\\begin{array}{l}{\\frac{x_{n+1}}{2}, \\text { jika n ganjil }} \\\\ {\\frac{\\frac{x_{n}}{2}+x_{\\frac{n}{2}+1}}{2}, \\text { jika n genap }}\\end{array}\\right. Jika Dikelompokkan Q_{j}=L_{j}+i \\frac{\\frac{j}{4} n-f k}{f} Q_{j}=L_{j}+i \\frac{\\frac{j}{4} n-f k}{f} Dengan : Qj = Kuartil ke-j j = 1, 2, 3 i = Interval kelas Lj = Tepi bawah kelas Qj fk = Frekuensi kumulatif sebelum kelas Qj f = Frekuensi kelas Qj n = Banyak data.","title":"Median"},{"location":"statistik_deskriptif/#mode-modus","text":"\u200b Modus adalah nilai yang mempunyai frekuensi terbesar dalam suatu kumpulan data. Modus berguna untuk mengetahui tingkat keseringan terjadinya suatu peristiwa. Modus dapat digunakan untuk semua skala pengukuran data mulai dari nominal hingga rasio. Meskipun demikian modus paling cocok digunakan untuk data yang diukur dengan skala pengukuran nominal. Rumus dalam mencari modus adalah: $$ \\mathrm{Mo}=\\mathrm{Tb}+\\mathrm{p} \\cdot\\left(\\frac{d_{1}}{d_{1}+d_{2}}\\right) $$ Keterangan: - Tb = Tepi bawah kelas modus - p = Panjang interval - d1 = selisih frekuensi kelas modus dengan frekuensi kelas sebelumnya - d2 = selisih frekuensi kelas modus dengan frekuensi kelas setelahnya","title":"Mode (Modus)"},{"location":"statistik_deskriptif/#standart-deviasi","text":"\u200b Standar deviasi adalah ukuran atau nilai statistik yang digunakan untuk mengukur jumlah variasi serta sebaran dari sejumlah nilai data. \u200b Secara khusus semakin rendah standar deviasi maka semakin mendekati rata-rata, sebaliknya jika semakin tinggi maka semakin lebar rentang variasi datanya. s=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n}} s=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n}} Keterangan: xi = nilai x ke i x bar = nilai rata-rata dari x n = banyaknya data","title":"Standart Deviasi"},{"location":"statistik_deskriptif/#varians","text":"\u200b Varians didefinisikan sebagai rata-rata dari skor penyimpangan kuadrat. dan variasi adalah nilai akar dari standart deviasi krn itu tidak terlalu beda jauh antara rumus tersebut. contohnya sebagai berikut: s^{2}=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n-1}} s^{2}=\\sqrt{\\frac{\\sum_{i=1}^{n}\\left(x_{1}-\\overline{x}\\right)^{2}}{n-1}}","title":"Varians"},{"location":"statistik_deskriptif/#quartile","text":"Quartile adalah pembagian 4 bagian data yang sama perbagiannya dan berada dalam salah satu dari 3 titik yang membagi rentang bagian data yang sama yang menjadikan, yang menjadikan Q1, Q2 = median, Q3. Q_{1}=x_{\\frac{1}{4}(n+1)} Q_{1}=x_{\\frac{1}{4}(n+1)} Q_{2}=x_{\\frac{1}{2}(n+1)} Q_{2}=x_{\\frac{1}{2}(n+1)} Q_{1}=x_{\\frac{3}{4}(n+1)} Q_{1}=x_{\\frac{3}{4}(n+1)}","title":"Quartile"},{"location":"statistik_deskriptif/#skewness","text":"skewness adalah ukuran dari asimetri dari distribusi probabilitas dari variabel acak bernilai nyata tentang nilai tengahnya. Nilai skewness bisa positif atau negatif, atau tidak terdefinisi. Untuk distribusi unimodal , condong negatif biasanya menunjukkan bahwa ekor berada di sisi kiri distribusi, dan condong positif menunjukkan bahwa ekor berada di sebelah kanan. sk=\\frac{\\overline{X}-Me}{s} sk=\\frac{\\overline{X}-Me}{s} Keterangan: - X bar = Rata Rata nilai X - Me = Median Data - s = simpangan baku (standart deviasi)","title":"Skewness"},{"location":"statistik_deskriptif/#penerapan-statistik-deskriptif","text":"","title":"Penerapan Statistik Deskriptif"},{"location":"statistik_deskriptif/#library","text":"Untuk yang pertama Siapkan data yang digunakan yaitu data sebanyak 500 dalam 5 fitur yaitu X1 s/d X2 dalam bentuk excel pemprosesannya menggunakan python dan membutuhkan library sebagai berikut: Pandas untuk manajemen data Scipy adalah kumpulan algoritma aritmatika lalu setelah itu mulai import library yang disiapkan tadi: import pandas as pd from scipy import stats","title":"Library"},{"location":"statistik_deskriptif/#managemen-data","text":"Selanjutnya olah Data yaitu olah data exel tadi, dengan kode berikut df = pd . read_excel ( data_M5.xlsx , usecols = [ 1 , 2 , 3 , 4 , 5 ])","title":"Managemen data"},{"location":"statistik_deskriptif/#olahdata","text":"Selanjutnya olah Data menggunakan variabel sementara untuk hasil keseluruhan data yang akan diolah mulai dari mean,median,modus(mode),min max,standart deviasi, quartile, dan skewnes dari beberapa vitur dari file exel tadi for i in df : print ( --- %s --- % i ) #to print title Q1 = df [ i ] . quantile ( 0.25 ) print ( Q1 = , Q1 ) Q2 = df [ i ] . quantile ( 0.5 ) print ( Q2 = , Q2 ) Q3 = df [ i ] . quantile ( 0.75 ) print ( Q3 = , Q3 ) Rata = df [ i ] . mean () print ( Mean = , Rata ) Std_dev = statistics . stdev ( df [ i ]) print ( Std Dev = , Std_dev ) Skewness = df [ i ] . skew () print ( Skewness = , Skewness , \\n )","title":"Olahdata"},{"location":"statistik_deskriptif/#hasil-data","text":"dari olahan data tersebut menghasilkan data tersebut menghasilkan data sebagai berikut ketida dihasilkan menggunakan kolom: code: df . describe () outpunya : x1 x2 x3 x4 x5 count 100.000000 100.000000 100.000000 100.000000 100.000000 mean 65.370000 65.910000 53.940000 61.620000 67.470000 median 66.500000 68.500000 57.000000 60.000000 70.500000 std 20.868833 22.992794 24.068849 18.415946 21.003345 min 20.000000 21.000000 10.000000 16.000000 21.000000 25% 49.750000 47.000000 37.000000 47.750000 55.000000 50% 66.500000 68.500000 57.000000 60.000000 70.500000 75% 81.250000 86.250000 72.000000 75.250000 83.500000 max 100.000000 100.000000 100.000000 99.000000 100.000000 skew -0.164192 -0.279515 -0.085728 0.092857 -0.542891","title":"Hasil data"},{"location":"statistik_deskriptif/#source","text":"Untuk file python ada di sini","title":"Source"}]}